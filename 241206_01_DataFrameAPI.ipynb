{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a4aff4c-64c5-4f68-b443-733149fe2f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"FirstSparkSessionApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a65d5465-2e8a-4c84-a6d5-8de22b453986",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format('csv').load('data/2015-summary.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42988f99-62df-482a-9b5f-f0e17bba5022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(DEST_COUNTRY_NAME,StringType,true),StructField(ORIGIN_COUNTRY_NAME,StringType,true),StructField(count,IntegerType,true)))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba2cc597-d67a-4944-a57f-8761c99db29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7173c807-fa8c-4b6c-8d1b-fdd81416ecb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f804fba2-92aa-4b23-ac9d-d383c1b3a7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DEST_COUNTRY_NAME|\n",
      "+-----------------+\n",
      "|    United States|\n",
      "|    United States|\n",
      "|    United States|\n",
      "|            Egypt|\n",
      "|    United States|\n",
      "+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SPARK DATA TABLE\n",
    "df.select(\"DEST_COUNTRY_NAME\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cd34325-1181-4658-98cf-a9fe1ce322a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"mobility_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76dfbc9c-9f98-4b03-a508-51a9a0d3091e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d926f76-5325-4582-950e-5056a6760089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|   DEST_COUNTRY_NAME|\n",
      "+--------------------+\n",
      "|            Anguilla|\n",
      "|              Russia|\n",
      "|            Paraguay|\n",
      "|             Senegal|\n",
      "|              Sweden|\n",
      "|            Kiribati|\n",
      "|              Guyana|\n",
      "|         Philippines|\n",
      "|            Djibouti|\n",
      "|            Malaysia|\n",
      "|           Singapore|\n",
      "|                Fiji|\n",
      "|              Turkey|\n",
      "|                Iraq|\n",
      "|             Germany|\n",
      "|              Jordan|\n",
      "|               Palau|\n",
      "|Turks and Caicos ...|\n",
      "|              France|\n",
      "|              Greece|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dup = df.select('DEST_COUNTRY_NAME').dropDuplicates()\n",
    "df_dup.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a05098e-4fb0-40e3-8449-9df7b838b30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dup.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66706874-579d-4e20-bd34-c69e388fec0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|   DEST_COUNTRY_NAME|\n",
      "+--------------------+\n",
      "|            Anguilla|\n",
      "|              Russia|\n",
      "|            Paraguay|\n",
      "|             Senegal|\n",
      "|              Sweden|\n",
      "|            Kiribati|\n",
      "|              Guyana|\n",
      "|         Philippines|\n",
      "|            Djibouti|\n",
      "|            Malaysia|\n",
      "|           Singapore|\n",
      "|                Fiji|\n",
      "|              Turkey|\n",
      "|                Iraq|\n",
      "|             Germany|\n",
      "|              Jordan|\n",
      "|               Palau|\n",
      "|Turks and Caicos ...|\n",
      "|              France|\n",
      "|              Greece|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/06 16:13:20 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    }
   ],
   "source": [
    "df_dup = df.select('DEST_COUNTRY_NAME').dropDuplicates().cache() #z캐시를 할때랑 하지 않을때의 차이는 4040포트 사이트에서 확인\n",
    "# 캐시를 쓰면 본래 사용되는 메모리가 줄어든다. \n",
    "df_dup.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee021034-669a-4c05-b437-7f3dedb944df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SPARK SQL\n",
    "spark.sql(\"select * from mobility_data\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26119668-22bf-425f-8991-c6c4a8398554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUP BY 집계\n",
    "'''\n",
    "select * from \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "beee302f-4e05-43e6-bcd1-dd689da180a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8eb9e21b-bc6b-41a6-b0dc-493a34ba3e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼을 추가하기\n",
    "df3 = df.withColumn('withInCountry', expr('ORIGIN_COUNTRY_NAME==DEST_COUNTRY_NAME'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7507848e-c3fc-4f3b-9eff-38ab356f63b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withInCountry|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "|    United States|            Romania|   15|        false|\n",
      "|    United States|            Croatia|    1|        false|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0c39dee-7092-413b-a003-80108908682b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+--------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|category|\n",
      "+-----------------+-------------------+-----+--------+\n",
      "|    United States|            Romania|   15|   upper|\n",
      "|    United States|            Croatia|    1|   under|\n",
      "+-----------------+-------------------+-----+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 컬럼을 추가하기(컬럼값의 조건식은 다음과 같음)\n",
    "df4 = df.withColumn('category', expr('CASE WHEN count<10 THEN \"under\" WHEN count>=10 THEN \"upper\" END '))  #조건식은 SQL문으로\n",
    "df4.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82841fe9-9d49-4bcd-95ec-b1ce3a503064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|count_double|\n",
      "+-----------------+-------------------+-----+------------+\n",
      "|    United States|            Romania|   15|          30|\n",
      "|    United States|            Croatia|    1|           2|\n",
      "+-----------------+-------------------+-----+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# count값의 2배를 계산하여 새로운 컬럼 추가\n",
    "df5 = df.withColumn('count_double', df['count'] * 2)\n",
    "df5.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d52d7dd1-cd23-48e1-97af-7d6700e87b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df5.where('count<5' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2be2f58f-583b-496b-ab45-d4b9320dd74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bbc333a7-693f-4ba6-900c-2eb2745981d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|count_double|\n",
      "+-----------------+-------------------+-----+------------+\n",
      "|    United States|            Croatia|    1|           2|\n",
      "|    United States|          Singapore|    1|           2|\n",
      "|    United States|          Gibraltar|    1|           2|\n",
      "|    United States|             Cyprus|    1|           2|\n",
      "|    United States|           Malaysia|    3|           6|\n",
      "|    United States|            Vietnam|    2|           4|\n",
      "|    United States|            Estonia|    1|           2|\n",
      "|    United States|            Hungary|    3|           6|\n",
      "|    United States|           Thailand|    4|           8|\n",
      "|    United States|            Liberia|    2|           4|\n",
      "|    United States|              Malta|    2|           4|\n",
      "|    United States|          Lithuania|    1|           2|\n",
      "|    United States|           Bulgaria|    1|           2|\n",
      "|    United States|            Georgia|    1|           2|\n",
      "|    United States|            Bahrain|    1|           2|\n",
      "|    United States|   Papua New Guinea|    1|           2|\n",
      "|    United States|          Greenland|    4|           8|\n",
      "|    United States|          Indonesia|    2|           4|\n",
      "|    United States|         Montenegro|    1|           2|\n",
      "|    United States|            Namibia|    1|           2|\n",
      "+-----------------+-------------------+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.where('count < 5').where('ORIGIN_COUNTRY_NAME != \"United States\" ').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "638ceaed-f789-47d2-9c88-3e7b3b5acf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "| ORIGIN_COUNTRY_NAME|\n",
      "+--------------------+\n",
      "|             Germany|\n",
      "|Turks and Caicos ...|\n",
      "|              France|\n",
      "|              Taiwan|\n",
      "|             Belgium|\n",
      "|             Ecuador|\n",
      "|           Nicaragua|\n",
      "|                Peru|\n",
      "|       United States|\n",
      "|               China|\n",
      "|      Cayman Islands|\n",
      "|               Italy|\n",
      "|               Spain|\n",
      "|                Cuba|\n",
      "|             Ireland|\n",
      "|              Panama|\n",
      "|           Hong Kong|\n",
      "|           Venezuela|\n",
      "|             Iceland|\n",
      "|         South Korea|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# count가 200 이상인 ORIGIN_COUNTRY_NAME 필터링\n",
    "count_above_200 = df5.filter(df5['count'] >= 200).select('ORIGIN_COUNTRY_NAME').distinct()\n",
    "\n",
    "count_above_200.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9dfeba84-a932-4f22-9d02-47406f9bc771",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 국내 여행이 아닌 데이터를 필터링하고, 횟수가 많은 ORIGIN_COUNTRY_NAME Top 10 추출\u001b[39;00m\n\u001b[1;32m      2\u001b[0m non_domestic_top10 \u001b[38;5;241m=\u001b[39m df5\u001b[38;5;241m.\u001b[39mfilter(df5[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDEST_COUNTRY_NAME\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m df5[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mORIGIN_COUNTRY_NAME\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mgroupBy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mORIGIN_COUNTRY_NAME\u001b[39m\u001b[38;5;124m'\u001b[39m) \\\n\u001b[0;32m----> 3\u001b[0m                         \u001b[38;5;241m.\u001b[39magg(\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcount\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_count\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39morderBy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_count\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 결과 출력\u001b[39;00m\n\u001b[1;32m      6\u001b[0m non_domestic_top10\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "# 국내 여행이 아닌 데이터를 필터링하고, 횟수가 많은 ORIGIN_COUNTRY_NAME Top 10 추출\n",
    "non_domestic_top10 = df5.filter(df5['DEST_COUNTRY_NAME'] != df5['ORIGIN_COUNTRY_NAME']).groupBy('ORIGIN_COUNTRY_NAME') \\\n",
    "                        .agg(sum('count').alias('total_count')).orderBy('total_count', ascending=False)\n",
    "\n",
    "# 결과 출력\n",
    "non_domestic_top10.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ffb89a88-7caf-4990-8258-ee8789c7af90",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54ccad6f-7ce9-4afd-aee6-9ed80a4afa43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/09 10:30:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"SecondSparkSessionApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aacd1bee-3f65-45c4-9c7d-d66e56d8de70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- empno: integer (nullable = true)\n",
      " |-- ename: string (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- mgr: integer (nullable = true)\n",
      " |-- hiredate: string (nullable = true)\n",
      " |-- sal: integer (nullable = true)\n",
      " |-- comm: integer (nullable = true)\n",
      " |-- deptno: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .load(\"data/emp.csv\")\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "076febe4-2cba-4734-8273-b9f1aba1aaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|ename|deptno|\n",
      "+-----+------+\n",
      "|SMITH|    20|\n",
      "|JONES|    20|\n",
      "|SCOTT|    20|\n",
      "|ADAMS|    20|\n",
      "| FORD|    20|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('ename', 'deptno').where('deptno=20').show() #조건을 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0afd59ab-440c-4369-bca0-3184d6c0350e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, countDistinct, approx_count_distinct, min, max, expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7c9f665-bef7-4cf5-a20e-f92907858371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|count(job)|\n",
      "+----------+\n",
      "|        15|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 카운트 집계\n",
    "df.select(count('job')).show() #count함수는 따로 정의해주어야함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e7067ba-7de6-49a0-a8ea-db6d6c1511a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      15|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr('count(*)').show() #이렇게 하면 null이 제외되며 위의 값과 비교해 null의 존재를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a62b2cf1-e1c2-40ca-8043-4060ea1f99c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('job').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d6604d7-165c-44b0-a6b9-82f396859ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|approx_count_distinct(job)|\n",
      "+--------------------------+\n",
      "|                         5|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(approx_count_distinct('job', 0.1)).show() #한번에 쓰는법, 성능이 조금 더 빠른 편, 옆에 0.1은 10%정도의 오차를 감수한다는 뜻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "828882b6-746b-47f4-b251-ecee0c60b1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|max(deptno)|\n",
      "+-----------+\n",
      "|         70|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(max('deptno')).show()  # deptno 컬럼의 최대값, 위에서 max를 쓰지 않으면 파이썬에 내장된 max를 쓰게 된다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cae6dbb5-1795-47c7-a9de-41b6650fa5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|min(deptno)|\n",
      "+-----------+\n",
      "|         10|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(min('deptno')).show()  # deptno 컬럼의 최대값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de40f8bc-effe-4df0-a42c-639717915a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:===================================================>  (191 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|sum(sal)|\n",
      "+--------+\n",
      "|   27975|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# df.select().distinct().sum()\n",
    "df.select('sal').distinct().agg({'sal': 'sum'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27d4585a-06cf-44b0-b66e-42bff8251c45",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m dfs \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mselect(\n\u001b[1;32m      2\u001b[0m     count(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msal\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_tx\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_salary\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      4\u001b[0m     avg(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msal\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_salary\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      5\u001b[0m     espr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean(sal)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m dfs\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "dfs = df.select(\n",
    "    count('sal').alias('total_tx'),\n",
    "    sum('sal').alias('total_salary'),\n",
    "    avg('sal').alias('avg_salary'),\n",
    "    espr('mean(sal)')\n",
    ")\n",
    "\n",
    "dfs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7fa159b9-4e90-47b2-8ce6-4a3c52530ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|      job|count|\n",
      "+---------+-----+\n",
      "|  ANALYST|    2|\n",
      "| SALESMAN|    4|\n",
      "|    CLERK|    5|\n",
      "|  MANAGER|    3|\n",
      "|PRESIDENT|    1|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('job').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8cc79343-126b-4bd4-9db2-82d68eb53805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|      job|           SAL_AVG|\n",
      "+---------+------------------+\n",
      "|  ANALYST|            3000.0|\n",
      "| SALESMAN|            1400.0|\n",
      "|    CLERK|            1470.0|\n",
      "|  MANAGER|2758.3333333333335|\n",
      "|PRESIDENT|            5000.0|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs = df.groupBy('job').agg(expr('avg(sal) as SAL_AVG'))\n",
    "dfs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cc72e066-f6c3-4cdc-b290-45ba9e67432f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|      job|   stddev_pop(sal)|\n",
      "+---------+------------------+\n",
      "|  ANALYST|               0.0|\n",
      "| SALESMAN|154.11035007422439|\n",
      "|    CLERK| 880.6815542521599|\n",
      "|  MANAGER|223.91714737574006|\n",
      "|PRESIDENT|               0.0|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('job').agg(expr('stddev_pop(sal)')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef950dce-6940-46ee-b80a-030fa09c210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 윈도우 함수 \n",
    "# - 순위,정렬(rank, row_number, dense_rank)\n",
    "# - 누계(sum, avg, max, min, over())\n",
    "# - 이동평균(over+rowsBetween, rangeBetween)\n",
    "# - 시차, 선행(lag, lead)\n",
    "# ex) 세션 구간내 분석, 특정 시간동안 일어난 활동 그룹화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "52c168c9-a9c1-469a-a544-dded2c69a09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import desc, rank\n",
    "\n",
    "# 윈도우 명세 설정\n",
    "windowspec = Window.orderBy(desc('sal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a5ca9afd-8570-459c-b913-61c3d43415a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'RANK() OVER (ORDER BY sal DESC NULLS LAST unspecifiedframe$())'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salAllRank = rank().over(windowspec)\n",
    "salAllRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "596fe20c-e081-4341-8491-28c2cbaa0f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/09 13:39:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+-----------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|salary_rank|\n",
      "+-----+------+---------+----+----------+----+----+------+-----------+\n",
      "| 7839|  KING|PRESIDENT|null|1981-11-17|5000|null|    10|          1|\n",
      "| 9292|  JACK|    CLERK|7782|1982-01-23|3200|null|    70|          2|\n",
      "| 7788| SCOTT|  ANALYST|7566|1987-04-19|3000|null|    20|          3|\n",
      "| 7902|  FORD|  ANALYST|7566|1981-12-03|3000|null|    20|          3|\n",
      "| 7566| JONES|  MANAGER|7839|1981-04-02|2975|null|    20|          5|\n",
      "| 7698| BLAKE|  MANAGER|7839|1981-05-01|2850|null|    30|          6|\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|null|    10|          7|\n",
      "| 7499| ALLEN| SALESMAN|7698|1981-02-20|1600| 300|    30|          8|\n",
      "| 7844|TURNER| SALESMAN|7698|1981-09-08|1500|   0|    30|          9|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|null|    10|         10|\n",
      "| 7521|  WARD| SALESMAN|7698|1981-02-22|1250| 500|    30|         11|\n",
      "| 7654|MARTIN| SALESMAN|7698|1981-09-28|1250|1400|    30|         11|\n",
      "| 7876| ADAMS|    CLERK|7788|1987-05-23|1100|null|    20|         13|\n",
      "| 7900| JAMES|    CLERK|7698|1981-12-03| 950|null|    30|         14|\n",
      "| 7369| SMITH|    CLERK|7902|1980-12-17| 800|null|    20|         15|\n",
      "+-----+------+---------+----+----------+----+----+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"salary_rank\", salAllRank).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ddce1e77-f896-4029-a3d5-4adc23857bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+\n",
      "|empno|salary_rank|\n",
      "+-----+-----------+\n",
      "| 7369|        800|\n",
      "| 7499|       1600|\n",
      "| 7521|       1250|\n",
      "| 7566|       2975|\n",
      "| 7654|       1250|\n",
      "| 7698|       2850|\n",
      "| 7782|       2450|\n",
      "| 7788|       3000|\n",
      "| 7839|       5000|\n",
      "| 7844|       1500|\n",
      "| 7876|       1100|\n",
      "| 7900|        950|\n",
      "| 7902|       3000|\n",
      "| 7934|       1300|\n",
      "| 9292|       3200|\n",
      "+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.select('empno', col('sal').alias('salary_rank')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3ebfee55-da15-4e04-8e29-fefc421f2280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+\n",
      "|empno|salary_rank|\n",
      "+-----+-----------+\n",
      "| 7839|          1|\n",
      "| 9292|          2|\n",
      "| 7788|          3|\n",
      "| 7902|          3|\n",
      "| 7566|          5|\n",
      "| 7698|          6|\n",
      "| 7782|          7|\n",
      "| 7499|          8|\n",
      "| 7844|          9|\n",
      "| 7934|         10|\n",
      "| 7521|         11|\n",
      "| 7654|         11|\n",
      "| 7876|         13|\n",
      "| 7900|         14|\n",
      "| 7369|         15|\n",
      "+-----+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/09 13:52:42 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import rank\n",
    "\n",
    "\n",
    "\n",
    "df = df.withColumn('salary_rank', rank().over(windowSpec))\n",
    "\n",
    "df.select('empno', 'salary_rank').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4446f089-a57c-4b8e-bd8d-c9bf695767e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSpec = Window.orderBy(col('sal').desc())\n",
    "windowspec1 = windowSpec.partitionBy('job').orderBy(desc('sal'))\n",
    "salJobRank = rank().over(windowspec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8c9b7c63-f416-4a6e-9426-8eae533d4281",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'WindowSpec' object has no attribute 'alias'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m df\u001b[38;5;241m.\u001b[39mselect(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mename\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msal\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mwindowspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msalJobRank\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m )\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'WindowSpec' object has no attribute 'alias'"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "    'job', 'ename', 'sal',\n",
    "    windowspec.alias('salJobRank')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ad71b1b1-f7b5-42a9-b6a8-0d9e0079860c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----+----------+\n",
      "|      job| ename| sal|salJobRank|\n",
      "+---------+------+----+----------+\n",
      "|  ANALYST| SCOTT|3000|         1|\n",
      "|  ANALYST|  FORD|3000|         1|\n",
      "| SALESMAN| ALLEN|1600|         1|\n",
      "| SALESMAN|TURNER|1500|         2|\n",
      "| SALESMAN|  WARD|1250|         3|\n",
      "| SALESMAN|MARTIN|1250|         3|\n",
      "|    CLERK|  JACK|3200|         1|\n",
      "|    CLERK|MILLER|1300|         2|\n",
      "|    CLERK| ADAMS|1100|         3|\n",
      "|    CLERK| JAMES| 950|         4|\n",
      "|    CLERK| SMITH| 800|         5|\n",
      "|  MANAGER| JONES|2975|         1|\n",
      "|  MANAGER| BLAKE|2850|         2|\n",
      "|  MANAGER| CLARK|2450|         3|\n",
      "|PRESIDENT|  KING|5000|         1|\n",
      "+---------+------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "windowSpec = Window.partitionBy('job').orderBy(col('sal').desc())\n",
    "df = df.withColumn('salJobRank', rank().over(windowSpec))\n",
    "df.select('job', 'ename', 'sal', 'salJobRank').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a57622-0e5a-4e09-9be7-12979ffae4bc",
   "metadata": {},
   "source": [
    "new_df = df.withColumn('dept_salary_rank', dense_rank().over(dept_window_spec))\n",
    "new_df.select('ename', 'deptno', 'sal', 'dept_salary_rank').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8bc9b1e7-fedd-45bb-9a1b-44ee6c1d2046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|deptno|        avg_salary|\n",
      "+------+------------------+\n",
      "|    20|            2175.0|\n",
      "|    10|2916.6666666666665|\n",
      "|    70|            3200.0|\n",
      "|    30|1566.6666666666667|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 연습 : 부서별로 평균 급여를 구해보기\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "dept_avg_salary = df.groupBy('deptno').agg(avg('sal').alias('avg_salary'))\n",
    "dept_avg_salary.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cd78a7d9-4a46-46ff-b85a-e05de4168ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+-----------+-----------+\n",
      "| ename|deptno| sal|prev_salary|next_salary|\n",
      "+------+------+----+-----------+-----------+\n",
      "| SMITH|    20| 800|       null|       2975|\n",
      "| JONES|    20|2975|        800|       3000|\n",
      "| SCOTT|    20|3000|       2975|       1100|\n",
      "| ADAMS|    20|1100|       3000|       3000|\n",
      "|  FORD|    20|3000|       1100|       null|\n",
      "| CLARK|    10|2450|       null|       5000|\n",
      "|  KING|    10|5000|       2450|       1300|\n",
      "|MILLER|    10|1300|       5000|       null|\n",
      "|  JACK|    70|3200|       null|       null|\n",
      "| ALLEN|    30|1600|       null|       1250|\n",
      "|  WARD|    30|1250|       1600|       1250|\n",
      "|MARTIN|    30|1250|       1250|       2850|\n",
      "| BLAKE|    30|2850|       1250|       1500|\n",
      "|TURNER|    30|1500|       2850|        950|\n",
      "| JAMES|    30| 950|       1500|       null|\n",
      "+------+------+----+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lag, lead\n",
    "\n",
    "# 부서별로 empno 기준으로 정렬된 윈도우 스펙 정의\n",
    "row_window_spec = Window.partitionBy('deptno').orderBy('empno')\n",
    "\n",
    "# 이전 급여와 다음 급여 컬럼 추가\n",
    "lead_lag_sal_df = df.withColumn('prev_salary', lag('sal').over(row_window_spec)) \\\n",
    "    .withColumn('next_salary', lead('sal').over(row_window_spec))\n",
    "\n",
    "# 필요한 열만 선택하여 출력\n",
    "lead_lag_sal_df.select('ename', 'deptno', 'sal', 'prev_salary', 'next_salary').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0ef46d-5bde-472a-8d67-47a26ab31c3d",
   "metadata": {},
   "source": [
    "=\n",
    "SELECT \n",
    "    ename, \n",
    "    deptno, \n",
    "    sal, \n",
    "    LAG(sal) OVER(PARTITION BY deptno ORDER BY empno) AS prev_salary, \n",
    "    LEAD(sal) OVER(PARTITION BY deptno ORDER BY empno) AS next_salary\n",
    "FROM emp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd06160-4296-477d-a0cd-f5f96810018e",
   "metadata": {},
   "source": [
    "# rollup과 cube : group by랑 유사한 기능을 하나 \n",
    "rollup : 계층적집계, 부분합, 총합\n",
    "cube : 모든 값으로 부분합, 결함 가능한 모든 값의 부분합을 구한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bba821a6-9e9b-4c4d-80d2-123a2e930e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[empno: int, ename: string, job: string, mgr: int, hiredate: string, sal: int, comm: int, deptno: int, salary_rank: int, salJobRank: int]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9716b31d-21d7-4974-bb60-944a765d2d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-----+------------+\n",
      "|deptno|      job|count|total_salary|\n",
      "+------+---------+-----+------------+\n",
      "|    20|  ANALYST|    2|        6000|\n",
      "|    20|  MANAGER|    1|        2975|\n",
      "|    30|  MANAGER|    1|        2850|\n",
      "|    70|    CLERK|    1|        3200|\n",
      "|    30| SALESMAN|    4|        5600|\n",
      "|    30|    CLERK|    1|         950|\n",
      "|    20|    CLERK|    2|        1900|\n",
      "|    10|PRESIDENT|    1|        5000|\n",
      "|    10|    CLERK|    1|        1300|\n",
      "|    10|  MANAGER|    1|        2450|\n",
      "+------+---------+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 그룹화를 진행\n",
    "\n",
    "from pyspark.sql.functions import count, sum\n",
    "\n",
    "# 그룹화를 진행하고 집계 연산 수행\n",
    "df.groupBy('deptno', 'job').agg(\n",
    "    count('*').alias('count'),\n",
    "    sum('sal').alias('total_salary')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "367f4ff9-8e02-4e05-9561-0fc9adcb3885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+--------+\n",
      "|deptno|      job|count(1)|max(sal)|\n",
      "+------+---------+--------+--------+\n",
      "|  null|     null|      15|    5000|\n",
      "|    10|     null|       3|    5000|\n",
      "|    10|    CLERK|       1|    1300|\n",
      "|    10|  MANAGER|       1|    2450|\n",
      "|    10|PRESIDENT|       1|    5000|\n",
      "|    20|     null|       5|    3000|\n",
      "|    20|  ANALYST|       2|    3000|\n",
      "|    20|    CLERK|       2|    1100|\n",
      "|    20|  MANAGER|       1|    2975|\n",
      "|    30|     null|       6|    2850|\n",
      "|    30|    CLERK|       1|     950|\n",
      "|    30|  MANAGER|       1|    2850|\n",
      "|    30| SALESMAN|       4|    1600|\n",
      "|    70|     null|       1|    3200|\n",
      "|    70|    CLERK|       1|    3200|\n",
      "+------+---------+--------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.rollup('deptno', 'job').agg(count('*'), max('sal')).orderBy('deptno','job').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755b6ecf-f833-418b-acc4-0d4d8ecb6d60",
   "metadata": {},
   "source": [
    "df.cube('deptno', 'job').agg(count('*'), sum('sal')).orderBy('deptno','job').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dbe61469-5786-403a-8c2b-562c61a47ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-----+-------+-------+\n",
      "|deptno|      job|count|max_sal|min_sal|\n",
      "+------+---------+-----+-------+-------+\n",
      "|  null|     null|   15|   5000|    800|\n",
      "|    10|     null|    3|   5000|   1300|\n",
      "|    10|    CLERK|    1|   1300|   1300|\n",
      "|    10|  MANAGER|    1|   2450|   2450|\n",
      "|    10|PRESIDENT|    1|   5000|   5000|\n",
      "|    20|     null|    5|   3000|    800|\n",
      "|    20|  ANALYST|    2|   3000|   3000|\n",
      "|    20|    CLERK|    2|   1100|    800|\n",
      "|    20|  MANAGER|    1|   2975|   2975|\n",
      "|    30|     null|    6|   2850|    950|\n",
      "|    30|    CLERK|    1|    950|    950|\n",
      "|    30|  MANAGER|    1|   2850|   2850|\n",
      "|    30| SALESMAN|    4|   1600|   1250|\n",
      "|    70|     null|    1|   3200|   3200|\n",
      "|    70|    CLERK|    1|   3200|   3200|\n",
      "+------+---------+-----+-------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.rollup('deptno', 'job').agg(\n",
    "    count('*').alias('count'),\n",
    "    max('sal').alias('max_sal'),\n",
    "    min('sal').alias('min_sal')\n",
    ").orderBy('deptno', 'job').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7f6b00-b898-4014-a3f8-a2ec6e49e17c",
   "metadata": {},
   "source": [
    "```sql\n",
    "SELECT \n",
    "    deptno, \n",
    "    job, \n",
    "    MAX(sal) AS max_sal, \n",
    "    MIN(sal) AS min_sal\n",
    "FROM emp\n",
    "GROUP BY ROLLUP(deptno, job);\n",
    "ORER BY deptno, job;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a2a941f8-0254-4287-979a-f240463416e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|      job|        avg_salary|\n",
      "+---------+------------------+\n",
      "|  ANALYST|            3000.0|\n",
      "| SALESMAN|            1400.0|\n",
      "|    CLERK|            1470.0|\n",
      "|  MANAGER|2758.3333333333335|\n",
      "|PRESIDENT|            5000.0|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('job').agg(avg('sal').alias('avg_salary')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ebe8ddb9-1668-41d6-a2b2-364854437c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------------------+----------+\n",
      "|deptno|      job|        avg_salary|max_salary|\n",
      "+------+---------+------------------+----------+\n",
      "|  null|     null|2148.3333333333335|      5000|\n",
      "|  null|  ANALYST|            3000.0|      3000|\n",
      "|  null|    CLERK|            1470.0|      3200|\n",
      "|  null|  MANAGER|2758.3333333333335|      2975|\n",
      "|  null|PRESIDENT|            5000.0|      5000|\n",
      "|  null| SALESMAN|            1400.0|      1600|\n",
      "|    10|     null|2916.6666666666665|      5000|\n",
      "|    10|    CLERK|            1300.0|      1300|\n",
      "|    10|  MANAGER|            2450.0|      2450|\n",
      "|    10|PRESIDENT|            5000.0|      5000|\n",
      "|    20|     null|            2175.0|      3000|\n",
      "|    20|  ANALYST|            3000.0|      3000|\n",
      "|    20|    CLERK|             950.0|      1100|\n",
      "|    20|  MANAGER|            2975.0|      2975|\n",
      "|    30|     null|1566.6666666666667|      2850|\n",
      "|    30|    CLERK|             950.0|       950|\n",
      "|    30|  MANAGER|            2850.0|      2850|\n",
      "|    30| SALESMAN|            1400.0|      1600|\n",
      "|    70|     null|            3200.0|      3200|\n",
      "|    70|    CLERK|            3200.0|      3200|\n",
      "+------+---------+------------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.cube('deptno', 'job').agg(avg('sal').alias('avg_salary'),max('sal').alias('max_salary')).orderBy('deptno', 'job').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "13b92ff6-644c-40de-b9c3-5a59227b41a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e54937-8b83-409e-a316-51f273424908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed773c0c-3f9a-402a-849f-b56f17f5b1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f55992b-6b8e-47be-a1ef-7b23d7476de8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spark_start)",
   "language": "python",
   "name": "spark_start"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
